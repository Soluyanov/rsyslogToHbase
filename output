# rsyslogToHbase

[hbase@c6402 ~]$ /bin/spark-submit --master local[2] --class com.test.core.strea             ming.Fake --files  /usr/hdp/current/hbase-client/conf/hbase-site.xml --jars /usr             /hdp/2.5.3.0-37/phoenix/phoenix-server.jar /home/test-streaming-0.1-SNAPSHOT.jar              c6402.ambari.apache.org my-consumer-group test 2 hdfs://c6402.ambari.apache.org             :8020/user/hdfs/newdir/parquetToday  hdfs://c6402.ambari.apache.org:8020/user/hd             fs/newdir/
17/03/21 14:50:44 INFO SparkContext: Running Spark version 1.6.2
17/03/21 14:50:46 INFO SecurityManager: Changing view acls to: hbase
17/03/21 14:50:46 INFO SecurityManager: Changing modify acls to: hbase
17/03/21 14:50:46 INFO SecurityManager: SecurityManager: authentication disabled             ; ui acls disabled; users with view permissions: Set(hbase); users with modify p             ermissions: Set(hbase)
17/03/21 14:50:49 INFO Utils: Successfully started service 'sparkDriver' on port              34069.
17/03/21 14:50:50 INFO Slf4jLogger: Slf4jLogger started
17/03/21 14:50:50 INFO Remoting: Starting remoting
17/03/21 14:50:50 INFO Utils: Successfully started service 'sparkDriverActorSyst             em' on port 39763.
17/03/21 14:50:50 INFO Remoting: Remoting started; listening on addresses :[akka             .tcp://sparkDriverActorSystem@172.16.6.158:39763]
17/03/21 14:50:50 INFO SparkEnv: Registering MapOutputTracker
17/03/21 14:50:50 INFO SparkEnv: Registering BlockManagerMaster
17/03/21 14:50:50 INFO DiskBlockManager: Created local directory at /tmp/blockmg             r-6b1b9dcd-04d1-4197-9289-5c4ad720a950
17/03/21 14:50:50 INFO MemoryStore: MemoryStore started with capacity 517.4 MB
17/03/21 14:50:51 INFO SparkEnv: Registering OutputCommitCoordinator
17/03/21 14:50:52 INFO Server: jetty-8.y.z-SNAPSHOT
17/03/21 14:50:52 WARN AbstractLifeCycle: FAILED SelectChannelConnector@0.0.0.0:             4040: java.net.BindException: Адрес уже используется
java.net.BindException: Адрес уже используется
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:433)
        at sun.nio.ch.Net.bind(Net.java:425)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:             223)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.spark-project.jetty.server.nio.SelectChannelConnector.open(Select             ChannelConnector.java:187)
        at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConn             ector.java:316)
        at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(Sel             ectChannelConnector.java:265)
        at org.spark-project.jetty.util.component.AbstractLifeCycle.start(Abstra             ctLifeCycle.java:64)
        at org.spark-project.jetty.server.Server.doStart(Server.java:293)
        at org.spark-project.jetty.util.component.AbstractLifeCycle.start(Abstra             ctLifeCycle.java:64)
        at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$conne             ct$1(JettyUtils.scala:252)
        at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
        at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
        at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$             sp(Utils.scala:2024)
        at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
        at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2015)
        at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262             )
        at org.apache.spark.ui.WebUI.bind(WebUI.scala:137)
        at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:48             1)
        at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:48             1)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
        at com.test.core.streaming.Fake$.main(Fake.scala:77)
        at com.test.core.streaming.Fake.main(Fake.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.             java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAcces             sorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:497)
        at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSub             mit$$runMain(SparkSubmit.scala:738)
        at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:18             1)
        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
17/03/21 14:50:52 WARN AbstractLifeCycle: FAILED org.spark-project.jetty.server.             Server@99a65d3: java.net.BindException: Адрес уже используется
java.net.BindException: Адрес уже используется
        at sun.nio.ch.Net.bind0(Native Method)
        at sun.nio.ch.Net.bind(Net.java:433)
        at sun.nio.ch.Net.bind(Net.java:425)
        at sun.nio.ch.ServerSocketChannelImpl.bind(ServerSocketChannelImpl.java:             223)
        at sun.nio.ch.ServerSocketAdaptor.bind(ServerSocketAdaptor.java:74)
        at org.spark-project.jetty.server.nio.SelectChannelConnector.open(Select             ChannelConnector.java:187)
        at org.spark-project.jetty.server.AbstractConnector.doStart(AbstractConn             ector.java:316)
        at org.spark-project.jetty.server.nio.SelectChannelConnector.doStart(Sel             ectChannelConnector.java:265)
        at org.spark-project.jetty.util.component.AbstractLifeCycle.start(Abstra             ctLifeCycle.java:64)
        at org.spark-project.jetty.server.Server.doStart(Server.java:293)
        at org.spark-project.jetty.util.component.AbstractLifeCycle.start(Abstra             ctLifeCycle.java:64)
        at org.apache.spark.ui.JettyUtils$.org$apache$spark$ui$JettyUtils$$conne             ct$1(JettyUtils.scala:252)
        at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
        at org.apache.spark.ui.JettyUtils$$anonfun$5.apply(JettyUtils.scala:262)
        at org.apache.spark.util.Utils$$anonfun$startServiceOnPort$1.apply$mcVI$             sp(Utils.scala:2024)
        at scala.collection.immutable.Range.foreach$mVc$sp(Range.scala:141)
        at org.apache.spark.util.Utils$.startServiceOnPort(Utils.scala:2015)
        at org.apache.spark.ui.JettyUtils$.startJettyServer(JettyUtils.scala:262             )
        at org.apache.spark.ui.WebUI.bind(WebUI.scala:137)
        at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:48             1)
        at org.apache.spark.SparkContext$$anonfun$13.apply(SparkContext.scala:48             1)
        at scala.Option.foreach(Option.scala:236)
        at org.apache.spark.SparkContext.<init>(SparkContext.scala:481)
        at com.test.core.streaming.Fake$.main(Fake.scala:77)
        at com.test.core.streaming.Fake.main(Fake.scala)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.             java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAcces             sorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:497)
        at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSub             mit$$runMain(SparkSubmit.scala:738)
        at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:18             1)
        at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:206)
        at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:121)
        at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             ages/stage/kill,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/ap             i,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,n             ull}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             atic,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/ex             ecutors/threadDump/json,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/ex             ecutors/threadDump,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/ex             ecutors/json,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/ex             ecutors,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/en             vironment/json,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/en             vironment,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             orage/rdd/json,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             orage/rdd,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             orage/json,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             orage,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             ages/pool/json,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             ages/pool,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             ages/stage/json,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             ages/stage,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             ages/json,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             ages,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jo             bs/job/json,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jo             bs/job,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jo             bs/json,null}
17/03/21 14:50:52 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jo             bs,null}
17/03/21 14:50:52 WARN Utils: Service 'SparkUI' could not bind on port 4040. Att             empting port 4041.
17/03/21 14:50:52 INFO Server: jetty-8.y.z-SNAPSHOT
17/03/21 14:50:53 INFO AbstractConnector: Started SelectChannelConnector@0.0.0.0             :4041
17/03/21 14:50:53 INFO Utils: Successfully started service 'SparkUI' on port 404             1.
17/03/21 14:50:53 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://             172.16.6.158:4041
17/03/21 14:50:53 INFO HttpFileServer: HTTP File server directory is /tmp/spark-             87195cb0-c2fd-4ce7-aea2-317fe9dae763/httpd-c2f45fcb-b5d4-42fd-aea9-ca655988dc74
17/03/21 14:50:53 INFO HttpServer: Starting HTTP Server
17/03/21 14:50:53 INFO Server: jetty-8.y.z-SNAPSHOT
17/03/21 14:50:53 INFO AbstractConnector: Started SocketConnector@0.0.0.0:35944
17/03/21 14:50:53 INFO Utils: Successfully started service 'HTTP file server' on              port 35944.
17/03/21 14:50:53 INFO SparkContext: Added JAR file:/usr/hdp/2.5.3.0-37/phoenix/             phoenix-server.jar at http://172.16.6.158:35944/jars/phoenix-server.jar with tim             estamp 1490097053968
17/03/21 14:50:54 INFO SparkContext: Added JAR file:/home/test-streaming-0.1-SNA             PSHOT.jar at http://172.16.6.158:35944/jars/test-streaming-0.1-SNAPSHOT.jar with              timestamp 1490097054901
17/03/21 14:50:57 INFO Utils: Copying /usr/hdp/current/hbase-client/conf/hbase-s             ite.xml to /tmp/spark-87195cb0-c2fd-4ce7-aea2-317fe9dae763/userFiles-d6a96f8e-3f             46-4037-8f9f-0eb5272f85f7/hbase-site.xml
17/03/21 14:50:57 INFO SparkContext: Added file file:/usr/hdp/current/hbase-clie             nt/conf/hbase-site.xml at file:/usr/hdp/current/hbase-client/conf/hbase-site.xml              with timestamp 1490097057649
17/03/21 14:50:58 INFO Executor: Starting executor ID driver on host localhost
17/03/21 14:50:58 INFO Utils: Successfully started service 'org.apache.spark.net             work.netty.NettyBlockTransferService' on port 46846.
17/03/21 14:50:58 INFO NettyBlockTransferService: Server created on 46846
17/03/21 14:50:58 INFO BlockManagerMaster: Trying to register BlockManager
17/03/21 14:50:58 INFO BlockManagerMasterEndpoint: Registering block manager loc             alhost:46846 with 517.4 MB RAM, BlockManagerId(driver, localhost, 46846)
17/03/21 14:50:58 INFO BlockManagerMaster: Registered BlockManager
17/03/21 14:51:03 INFO EventLoggingListener: Logging events to hdfs:///spark-his             tory/local-1490097058164
17/03/21 14:51:20 INFO MemoryStore: Block broadcast_0 stored as values in memory              (estimated size 385.5 KB, free 385.5 KB)
17/03/21 14:51:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in              memory (estimated size 33.5 KB, free 419.0 KB)
17/03/21 14:51:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on l             ocalhost:46846 (size: 33.5 KB, free: 517.4 MB)
17/03/21 14:51:20 INFO SparkContext: Created broadcast 0 from save at Fake.scala             :104
17/03/21 14:51:20 INFO RecoverableZooKeeper: Process identifier=hconnection-0x43             b172e3 connecting to ZooKeeper ensemble=c6402.ambari.apache.org:2181
17/03/21 14:51:20 INFO ZooKeeper: Client environment:zookeeper.version=3.4.6-37-             -1, built on 11/29/2016 17:59 GMT
17/03/21 14:51:20 INFO ZooKeeper: Client environment:host.name=c6402.ambari.apac             he.org
17/03/21 14:51:20 INFO ZooKeeper: Client environment:java.version=1.8.0_60
17/03/21 14:51:20 INFO ZooKeeper: Client environment:java.vendor=Oracle Corporat             ion
17/03/21 14:51:20 INFO ZooKeeper: Client environment:java.home=/usr/jdk64/jdk1.8             .0_60/jre
17/03/21 14:51:20 INFO ZooKeeper: Client environment:java.class.path=/usr/hdp/cu             rrent/spark-thriftserver/conf/:/usr/hdp/2.5.3.0-37/spark/lib/spark-assembly-1.6.             2.2.5.3.0-37-hadoop2.7.3.2.5.3.0-37.jar:/usr/hdp/2.5.3.0-37/spark/lib/datanucleu             s-api-jdo-3.2.6.jar:/usr/hdp/2.5.3.0-37/spark/lib/datanucleus-core-3.2.10.jar:/u             sr/hdp/2.5.3.0-37/spark/lib/datanucleus-rdbms-3.2.9.jar:/usr/hdp/current/hadoop-             client/conf/:/usr/hdp/current/hadoop-client/lib/aws-java-sdk-s3-1.10.6.jar:/usr/             hdp/current/hadoop-client/lib/aws-java-sdk-core-1.10.6.jar:/usr/hdp/current/hado             op-client/lib/aws-java-sdk-kms-1.10.6.jar
17/03/21 14:51:20 INFO ZooKeeper: Client environment:java.library.path=/usr/hdp/             current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux             -amd64-64:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
17/03/21 14:51:20 INFO ZooKeeper: Client environment:java.io.tmpdir=/tmp
17/03/21 14:51:20 INFO ZooKeeper: Client environment:java.compiler=<NA>
17/03/21 14:51:20 INFO ZooKeeper: Client environment:os.name=Linux
17/03/21 14:51:20 INFO ZooKeeper: Client environment:os.arch=amd64
17/03/21 14:51:20 INFO ZooKeeper: Client environment:os.version=3.10.0-514.10.2.             el7.x86_64
17/03/21 14:51:20 INFO ZooKeeper: Client environment:user.name=hbase
17/03/21 14:51:20 INFO ZooKeeper: Client environment:user.home=/home/hbase
17/03/21 14:51:20 INFO ZooKeeper: Client environment:user.dir=/home/hbase
17/03/21 14:51:20 INFO ZooKeeper: Initiating client connection, connectString=c6             402.ambari.apache.org:2181 sessionTimeout=90000 watcher=hconnection-0x43b172e30x             0, quorum=c6402.ambari.apache.org:2181, baseZNode=/hbase-unsecure
17/03/21 14:51:21 INFO ClientCnxn: Opening socket connection to server c6402.amb             ari.apache.org/172.16.6.158:2181. Will not attempt to authenticate using SASL (u             nknown error)
17/03/21 14:51:21 INFO ClientCnxn: Socket connection established to c6402.ambari             .apache.org/172.16.6.158:2181, initiating session
17/03/21 14:51:21 INFO ClientCnxn: Session establishment complete on server c640             2.ambari.apache.org/172.16.6.158:2181, sessionid = 0x15aeaba6d890612, negotiated              timeout = 40000
17/03/21 14:51:23 INFO HBaseAdmin: Started disable of shcExampleTable
17/03/21 14:51:26 INFO HBaseAdmin: Disabled shcExampleTable
17/03/21 14:51:27 INFO HBaseAdmin: Deleted shcExampleTable
17/03/21 14:51:30 INFO HBaseAdmin: Created shcExampleTable
17/03/21 14:51:30 INFO ConnectionManager$HConnectionImplementation: Closing mast             er protocol: MasterService
17/03/21 14:51:30 INFO ConnectionManager$HConnectionImplementation: Closing zook             eeper sessionid=0x15aeaba6d890612
17/03/21 14:51:30 INFO ZooKeeper: Session: 0x15aeaba6d890612 closed
17/03/21 14:51:30 INFO ClientCnxn: EventThread shut down
17/03/21 14:51:31 INFO deprecation: mapred.tip.id is deprecated. Instead, use ma             preduce.task.id
17/03/21 14:51:31 INFO deprecation: mapred.task.id is deprecated. Instead, use m             apreduce.task.attempt.id
17/03/21 14:51:31 INFO deprecation: mapred.task.is.map is deprecated. Instead, u             se mapreduce.task.ismap
17/03/21 14:51:31 INFO deprecation: mapred.task.partition is deprecated. Instead             , use mapreduce.task.partition
17/03/21 14:51:31 INFO deprecation: mapred.job.id is deprecated. Instead, use ma             preduce.job.id
17/03/21 14:51:31 INFO FileOutputCommitter: File Output Committer Algorithm vers             ion is 1
17/03/21 14:51:31 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _te             mporary folders under output directory:false, ignore cleanup failures: false
17/03/21 14:51:31 WARN FileOutputCommitter: Output Path is null in setupJob()
17/03/21 14:51:31 INFO SparkContext: Starting job: save at Fake.scala:104
17/03/21 14:51:31 INFO DAGScheduler: Got job 0 (save at Fake.scala:104) with 2 o             utput partitions
17/03/21 14:51:31 INFO DAGScheduler: Final stage: ResultStage 0 (save at Fake.sc             ala:104)
17/03/21 14:51:31 INFO DAGScheduler: Parents of final stage: List()
17/03/21 14:51:31 INFO DAGScheduler: Missing parents: List()
17/03/21 14:51:31 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[             3] at save at Fake.scala:104), which has no missing parents
17/03/21 14:51:32 INFO MemoryStore: Block broadcast_1 stored as values in memory              (estimated size 103.6 KB, free 522.6 KB)
17/03/21 14:51:32 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in              memory (estimated size 38.9 KB, free 561.5 KB)
17/03/21 14:51:32 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on l             ocalhost:46846 (size: 38.9 KB, free: 517.3 MB)
17/03/21 14:51:32 INFO SparkContext: Created broadcast 1 from broadcast at DAGSc             heduler.scala:1008
17/03/21 14:51:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage              0 (MapPartitionsRDD[3] at save at Fake.scala:104)
17/03/21 14:51:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks
17/03/21 14:51:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, lo             calhost, partition 0,PROCESS_LOCAL, 2487 bytes)
17/03/21 14:51:32 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1, lo             calhost, partition 1,PROCESS_LOCAL, 2487 bytes)
17/03/21 14:51:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/03/21 14:51:32 INFO Executor: Fetching file:/usr/hdp/current/hbase-client/con             f/hbase-site.xml with timestamp 1490097057649
17/03/21 14:51:32 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
17/03/21 14:51:32 INFO Utils: /usr/hdp/current/hbase-client/conf/hbase-site.xml              has been previously copied to /tmp/spark-87195cb0-c2fd-4ce7-aea2-317fe9dae763/us             erFiles-d6a96f8e-3f46-4037-8f9f-0eb5272f85f7/hbase-site.xml
17/03/21 14:51:32 INFO Executor: Fetching http://172.16.6.158:35944/jars/test-st             reaming-0.1-SNAPSHOT.jar with timestamp 1490097054901
17/03/21 14:51:32 INFO Utils: Fetching http://172.16.6.158:35944/jars/test-strea             ming-0.1-SNAPSHOT.jar to /tmp/spark-87195cb0-c2fd-4ce7-aea2-317fe9dae763/userFil             es-d6a96f8e-3f46-4037-8f9f-0eb5272f85f7/fetchFileTemp1534341203635883234.tmp
17/03/21 14:51:34 INFO Executor: Adding file:/tmp/spark-87195cb0-c2fd-4ce7-aea2-             317fe9dae763/userFiles-d6a96f8e-3f46-4037-8f9f-0eb5272f85f7/test-streaming-0.1-S             NAPSHOT.jar to class loader
17/03/21 14:51:34 INFO Executor: Fetching http://172.16.6.158:35944/jars/phoenix             -server.jar with timestamp 1490097053968
17/03/21 14:51:34 INFO Utils: Fetching http://172.16.6.158:35944/jars/phoenix-se             rver.jar to /tmp/spark-87195cb0-c2fd-4ce7-aea2-317fe9dae763/userFiles-d6a96f8e-3             f46-4037-8f9f-0eb5272f85f7/fetchFileTemp1326930119448343904.tmp
17/03/21 14:51:34 INFO Executor: Adding file:/tmp/spark-87195cb0-c2fd-4ce7-aea2-             317fe9dae763/userFiles-d6a96f8e-3f46-4037-8f9f-0eb5272f85f7/phoenix-server.jar t             o class loader
17/03/21 14:51:35 INFO FileOutputCommitter: File Output Committer Algorithm vers             ion is 1
17/03/21 14:51:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _te             mporary folders under output directory:false, ignore cleanup failures: false
17/03/21 14:51:35 INFO FileOutputCommitter: File Output Committer Algorithm vers             ion is 1
17/03/21 14:51:35 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _te             mporary folders under output directory:false, ignore cleanup failures: false
17/03/21 14:51:35 INFO RecoverableZooKeeper: Process identifier=hconnection-0x6c             2bfc88 connecting to ZooKeeper ensemble=c6402.ambari.apache.org:2181
17/03/21 14:51:35 INFO RecoverableZooKeeper: Process identifier=hconnection-0x35             9123b3 connecting to ZooKeeper ensemble=c6402.ambari.apache.org:2181
17/03/21 14:51:35 INFO ZooKeeper: Initiating client connection, connectString=c6             402.ambari.apache.org:2181 sessionTimeout=90000 watcher=hconnection-0x6c2bfc880x             0, quorum=c6402.ambari.apache.org:2181, baseZNode=/hbase-unsecure
17/03/21 14:51:35 INFO ZooKeeper: Initiating client connection, connectString=c6             402.ambari.apache.org:2181 sessionTimeout=90000 watcher=hconnection-0x359123b30x             0, quorum=c6402.ambari.apache.org:2181, baseZNode=/hbase-unsecure
17/03/21 14:51:36 INFO ClientCnxn: Opening socket connection to server c6402.amb             ari.apache.org/172.16.6.158:2181. Will not attempt to authenticate using SASL (u             nknown error)
17/03/21 14:51:36 INFO ClientCnxn: Opening socket connection to server c6402.amb             ari.apache.org/172.16.6.158:2181. Will not attempt to authenticate using SASL (u             nknown error)
17/03/21 14:51:36 INFO ClientCnxn: Socket connection established to c6402.ambari             .apache.org/172.16.6.158:2181, initiating session
17/03/21 14:51:36 INFO ClientCnxn: Socket connection established to c6402.ambari             .apache.org/172.16.6.158:2181, initiating session
17/03/21 14:51:36 INFO ClientCnxn: Session establishment complete on server c640             2.ambari.apache.org/172.16.6.158:2181, sessionid = 0x15aeaba6d890613, negotiated              timeout = 40000
17/03/21 14:51:36 INFO ClientCnxn: Session establishment complete on server c640             2.ambari.apache.org/172.16.6.158:2181, sessionid = 0x15aeaba6d890614, negotiated              timeout = 40000
17/03/21 14:51:36 INFO SparkHadoopMapRedUtil: No need to commit output of task b             ecause needsTaskCommit=false: attempt_201703211451_0000_m_000000_0
17/03/21 14:51:36 INFO SparkHadoopMapRedUtil: No need to commit output of task b             ecause needsTaskCommit=false: attempt_201703211451_0000_m_000001_1
17/03/21 14:51:36 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1864 by             tes result sent to driver
17/03/21 14:51:36 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1864 by             tes result sent to driver
17/03/21 14:51:36 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in              4474 ms on localhost (1/2)
17/03/21 14:51:36 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in              4442 ms on localhost (2/2)
17/03/21 14:51:36 INFO DAGScheduler: ResultStage 0 (save at Fake.scala:104) fini             shed in 4,528 s
17/03/21 14:51:36 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have              all completed, from pool
17/03/21 14:51:36 INFO DAGScheduler: Job 0 finished: save at Fake.scala:104, too             k 5,017604 s
17/03/21 14:51:36 WARN FileOutputCommitter: Output Path is null in commitJob()
17/03/21 14:51:37 INFO MemoryStore: Block broadcast_2 stored as values in memory              (estimated size 385.5 KB, free 947.0 KB)
17/03/21 14:51:37 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in              memory (estimated size 33.5 KB, free 980.5 KB)
17/03/21 14:51:37 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on l             ocalhost:46846 (size: 33.5 KB, free: 517.3 MB)
17/03/21 14:51:37 INFO SparkContext: Created broadcast 2 from save at Fake.scala             :114
17/03/21 14:51:37 INFO RecoverableZooKeeper: Process identifier=hconnection-0x24             0f2efd connecting to ZooKeeper ensemble=c6402.ambari.apache.org:2181
17/03/21 14:51:37 INFO ZooKeeper: Initiating client connection, connectString=c6             402.ambari.apache.org:2181 sessionTimeout=90000 watcher=hconnection-0x240f2efd0x             0, quorum=c6402.ambari.apache.org:2181, baseZNode=/hbase-unsecure
17/03/21 14:51:37 INFO ClientCnxn: Opening socket connection to server c6402.amb             ari.apache.org/172.16.6.158:2181. Will not attempt to authenticate using SASL (u             nknown error)
17/03/21 14:51:37 INFO ClientCnxn: Socket connection established to c6402.ambari             .apache.org/172.16.6.158:2181, initiating session
17/03/21 14:51:37 INFO ClientCnxn: Session establishment complete on server c640             2.ambari.apache.org/172.16.6.158:2181, sessionid = 0x15aeaba6d890615, negotiated              timeout = 40000
17/03/21 14:51:37 INFO HBaseAdmin: Started disable of shcExampleTable
17/03/21 14:51:39 INFO HBaseAdmin: Disabled shcExampleTable
17/03/21 14:51:43 INFO HBaseAdmin: Deleted shcExampleTable
17/03/21 14:51:46 INFO HBaseAdmin: Created shcExampleTable
17/03/21 14:51:46 INFO ConnectionManager$HConnectionImplementation: Closing mast             er protocol: MasterService
17/03/21 14:51:46 INFO ConnectionManager$HConnectionImplementation: Closing zook             eeper sessionid=0x15aeaba6d890615
17/03/21 14:51:46 INFO ZooKeeper: Session: 0x15aeaba6d890615 closed
17/03/21 14:51:46 INFO ClientCnxn: EventThread shut down
17/03/21 14:51:46 INFO FileOutputCommitter: File Output Committer Algorithm vers             ion is 1
17/03/21 14:51:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _te             mporary folders under output directory:false, ignore cleanup failures: false
17/03/21 14:51:46 WARN FileOutputCommitter: Output Path is null in setupJob()
17/03/21 14:51:46 INFO SparkContext: Starting job: save at Fake.scala:114
17/03/21 14:51:46 INFO DAGScheduler: Got job 1 (save at Fake.scala:114) with 2 o             utput partitions
17/03/21 14:51:46 INFO DAGScheduler: Final stage: ResultStage 1 (save at Fake.sc             ala:114)
17/03/21 14:51:46 INFO DAGScheduler: Parents of final stage: List()
17/03/21 14:51:46 INFO DAGScheduler: Missing parents: List()
17/03/21 14:51:46 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[             7] at save at Fake.scala:114), which has no missing parents
17/03/21 14:51:46 INFO MemoryStore: Block broadcast_3 stored as values in memory              (estimated size 103.6 KB, free 1084.1 KB)
17/03/21 14:51:46 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in              memory (estimated size 38.9 KB, free 1123.0 KB)
17/03/21 14:51:46 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on l             ocalhost:46846 (size: 38.9 KB, free: 517.3 MB)
17/03/21 14:51:46 INFO SparkContext: Created broadcast 3 from broadcast at DAGSc             heduler.scala:1008
17/03/21 14:51:46 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage              1 (MapPartitionsRDD[7] at save at Fake.scala:114)
17/03/21 14:51:46 INFO TaskSchedulerImpl: Adding task set 1.0 with 2 tasks
17/03/21 14:51:46 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2, lo             calhost, partition 0,PROCESS_LOCAL, 2471 bytes)
17/03/21 14:51:46 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 3, lo             calhost, partition 1,PROCESS_LOCAL, 2487 bytes)
17/03/21 14:51:46 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
17/03/21 14:51:46 INFO Executor: Running task 1.0 in stage 1.0 (TID 3)
17/03/21 14:51:46 INFO FileOutputCommitter: File Output Committer Algorithm vers             ion is 1
17/03/21 14:51:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _te             mporary folders under output directory:false, ignore cleanup failures: false
17/03/21 14:51:46 INFO RecoverableZooKeeper: Process identifier=hconnection-0x20             b74c98 connecting to ZooKeeper ensemble=c6402.ambari.apache.org:2181
17/03/21 14:51:46 INFO ZooKeeper: Initiating client connection, connectString=c6             402.ambari.apache.org:2181 sessionTimeout=90000 watcher=hconnection-0x20b74c980x             0, quorum=c6402.ambari.apache.org:2181, baseZNode=/hbase-unsecure
17/03/21 14:51:46 INFO FileOutputCommitter: File Output Committer Algorithm vers             ion is 1
17/03/21 14:51:46 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _te             mporary folders under output directory:false, ignore cleanup failures: false
17/03/21 14:51:46 INFO RecoverableZooKeeper: Process identifier=hconnection-0x41             287987 connecting to ZooKeeper ensemble=c6402.ambari.apache.org:2181
17/03/21 14:51:46 INFO ZooKeeper: Initiating client connection, connectString=c6             402.ambari.apache.org:2181 sessionTimeout=90000 watcher=hconnection-0x412879870x             0, quorum=c6402.ambari.apache.org:2181, baseZNode=/hbase-unsecure
17/03/21 14:51:46 INFO ClientCnxn: Opening socket connection to server c6402.amb             ari.apache.org/172.16.6.158:2181. Will not attempt to authenticate using SASL (u             nknown error)
17/03/21 14:51:46 INFO ClientCnxn: Opening socket connection to server c6402.amb             ari.apache.org/172.16.6.158:2181. Will not attempt to authenticate using SASL (u             nknown error)
17/03/21 14:51:46 INFO ClientCnxn: Socket connection established to c6402.ambari             .apache.org/172.16.6.158:2181, initiating session
17/03/21 14:51:46 INFO ClientCnxn: Socket connection established to c6402.ambari             .apache.org/172.16.6.158:2181, initiating session
17/03/21 14:51:46 INFO ClientCnxn: Session establishment complete on server c640             2.ambari.apache.org/172.16.6.158:2181, sessionid = 0x15aeaba6d890616, negotiated              timeout = 40000
17/03/21 14:51:47 INFO ClientCnxn: Session establishment complete on server c640             2.ambari.apache.org/172.16.6.158:2181, sessionid = 0x15aeaba6d890617, negotiated              timeout = 40000
17/03/21 14:51:47 INFO SparkHadoopMapRedUtil: No need to commit output of task b             ecause needsTaskCommit=false: attempt_201703211451_0001_m_000001_3
17/03/21 14:51:47 INFO Executor: Finished task 1.0 in stage 1.0 (TID 3). 1878 by             tes result sent to driver
17/03/21 14:51:47 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 3) in              569 ms on localhost (1/2)
17/03/21 14:51:47 INFO SparkHadoopMapRedUtil: No need to commit output of task b             ecause needsTaskCommit=false: attempt_201703211451_0001_m_000000_2
17/03/21 14:51:47 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 1878 by             tes result sent to driver
17/03/21 14:51:47 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in              607 ms on localhost (2/2)
17/03/21 14:51:47 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have              all completed, from pool
17/03/21 14:51:47 INFO DAGScheduler: ResultStage 1 (save at Fake.scala:114) fini             shed in 0,609 s
17/03/21 14:51:47 INFO DAGScheduler: Job 1 finished: save at Fake.scala:114, too             k 0,793979 s
17/03/21 14:51:47 WARN FileOutputCommitter: Output Path is null in commitJob()
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             atic/sql,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQ             L/execution/json,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQ             L/execution,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQ             L/json,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/SQ             L,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/me             trics/json,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             ages/stage/kill,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/ap             i,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/,n             ull}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             atic,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/ex             ecutors/threadDump/json,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/ex             ecutors/threadDump,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/ex             ecutors/json,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/ex             ecutors,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/en             vironment/json,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/en             vironment,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             orage/rdd/json,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             orage/rdd,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             orage/json,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             orage,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             ages/pool/json,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             ages/pool,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             ages/stage/json,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             ages/stage,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             ages/json,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/st             ages,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jo             bs/job/json,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jo             bs/job,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jo             bs/json,null}
17/03/21 14:51:47 INFO ContextHandler: stopped o.s.j.s.ServletContextHandler{/jo             bs,null}
17/03/21 14:51:47 INFO SparkUI: Stopped Spark web UI at http://172.16.6.158:4041
17/03/21 14:51:47 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEnd             point stopped!
17/03/21 14:51:47 INFO MemoryStore: MemoryStore cleared
17/03/21 14:51:47 INFO BlockManager: BlockManager stopped
17/03/21 14:51:47 INFO BlockManagerMaster: BlockManagerMaster stopped
17/03/21 14:51:47 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:              OutputCommitCoordinator stopped!
17/03/21 14:51:47 INFO RemoteActorRefProvider$RemotingTerminator: Shutting down              remote daemon.
17/03/21 14:51:47 INFO RemoteActorRefProvider$RemotingTerminator: Remote daemon              shut down; proceeding with flushing remote transports.
17/03/21 14:51:47 INFO SparkContext: Successfully stopped SparkContext
17/03/21 14:51:48 INFO ShutdownHookManager: Shutdown hook called
17/03/21 14:51:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-87195c             b0-c2fd-4ce7-aea2-317fe9dae763/httpd-c2f45fcb-b5d4-42fd-aea9-ca655988dc74
17/03/21 14:51:48 INFO RemoteActorRefProvider$RemotingTerminator: Remoting shut              down.
17/03/21 14:51:48 INFO ShutdownHookManager: Deleting directory /tmp/spark-87195c             b0-c2fd-4ce7-aea2-317fe9dae763
[hbase@c6402 ~]$

